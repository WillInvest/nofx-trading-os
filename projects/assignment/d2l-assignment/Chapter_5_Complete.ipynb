{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Multilayer Perceptrons\n",
    "\n",
    "This notebook contains ALL code from the D2L textbook chapter.\n",
    "\n",
    "**Kernel:** Use 'Python (d2l)'\n",
    "**Run cells in order.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.1 Multilayer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from d2l import torch as d2l\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)\n",
    "y = torch.relu(x)\n",
    "d2l.plot(x.detach(), y.detach(), 'x', 'relu(x)', figsize=(5, 2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.ones_like(x), retain_graph=True)\n",
    "d2l.plot(x.detach(), x.grad, 'x', 'grad of relu', figsize=(5, 2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.sigmoid(x)\n",
    "d2l.plot(x.detach(), y.detach(), 'x', 'sigmoid(x)', figsize=(5, 2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out previous gradients\n",
    "x.grad.data.zero_()\n",
    "y.backward(torch.ones_like(x),retain_graph=True)\n",
    "d2l.plot(x.detach(), x.grad, 'x', 'grad of sigmoid', figsize=(5, 2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tanh(x)\n",
    "d2l.plot(x.detach(), y.detach(), 'x', 'tanh(x)', figsize=(5, 2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out previous gradients\n",
    "x.grad.data.zero_()\n",
    "y.backward(torch.ones_like(x),retain_graph=True)\n",
    "d2l.plot(x.detach(), x.grad, 'x', 'grad of tanh', figsize=(5, 2.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.2 MLP Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPScratch(d2l.Classifier):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens, lr, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens) * sigma)\n",
    "        self.b1 = nn.Parameter(torch.zeros(num_hiddens))\n",
    "        self.W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs) * sigma)\n",
    "        self.b2 = nn.Parameter(torch.zeros(num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    a = torch.zeros_like(X)\n",
    "    return torch.max(X, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(MLPScratch)\n",
    "def forward(self, X):\n",
    "    X = d2l.reshape(X, (-1, self.num_inputs))\n",
    "    H = relu(d2l.matmul(X, self.W1) + self.b1)\n",
    "    return d2l.matmul(H, self.W2) + self.b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPScratch(num_inputs=784, num_outputs=10, num_hiddens=256, lr=0.1)\n",
    "data = d2l.FashionMNIST(batch_size=256)\n",
    "trainer = d2l.Trainer(max_epochs=10)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(d2l.Classifier):\n",
    "    def __init__(self, num_outputs, num_hiddens, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(nn.Flatten(), nn.LazyLinear(num_hiddens),\n",
    "                                 nn.ReLU(), nn.LazyLinear(num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(num_outputs=10, num_hiddens=256, lr=0.1)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.4 Numerical Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from d2l import torch as d2l\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)\n",
    "y = torch.sigmoid(x)\n",
    "y.backward(torch.ones_like(x))\n",
    "\n",
    "d2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad.numpy()],\n",
    "         legend=['sigmoid', 'gradient'], figsize=(4.5, 2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.normal(0, 1, size=(4, 4))\n",
    "print('a single matrix \\n',M)\n",
    "for i in range(100):\n",
    "    M = M @ torch.normal(0, 1, size=(4, 4))\n",
    "print('after multiplying 100 matrices\\n', M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_layer(X, dropout):\n",
    "    assert 0 <= dropout <= 1\n",
    "    if dropout == 1: return torch.zeros_like(X)\n",
    "    mask = (torch.rand(X.shape) > dropout).float()\n",
    "    return mask * X / (1.0 - dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(16, dtype = torch.float32).reshape((2, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutMLPScratch(d2l.Classifier):\n",
    "    def __init__(self, num_outputs, num_hiddens_1, num_hiddens_2,\n",
    "                 dropout_1, dropout_2, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lin1 = nn.LazyLinear(num_hiddens_1)\n",
    "        self.lin2 = nn.LazyLinear(num_hiddens_2)\n",
    "        self.lin3 = nn.LazyLinear(num_outputs)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        H1 = self.relu(self.lin1(X.reshape((X.shape[0], -1))))\n",
    "        if self.training:  \n",
    "            H1 = dropout_layer(H1, self.dropout_1)\n",
    "        H2 = self.relu(self.lin2(H1))\n",
    "        if self.training:\n",
    "            H2 = dropout_layer(H2, self.dropout_2)\n",
    "        return self.lin3(H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {'num_outputs':10, 'num_hiddens_1':256, 'num_hiddens_2':256,\n",
    "           'dropout_1':0.5, 'dropout_2':0.5, 'lr':0.1}\n",
    "model = DropoutMLPScratch(**hparams)\n",
    "data = d2l.FashionMNIST(batch_size=256)\n",
    "trainer = d2l.Trainer(max_epochs=10)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutMLP(d2l.Classifier):\n",
    "    def __init__(self, num_outputs, num_hiddens_1, num_hiddens_2,\n",
    "                 dropout_1, dropout_2, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(), nn.LazyLinear(num_hiddens_1), nn.ReLU(), \n",
    "            nn.Dropout(dropout_1), nn.LazyLinear(num_hiddens_2), nn.ReLU(), \n",
    "            nn.Dropout(dropout_2), nn.LazyLinear(num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DropoutMLP(**hparams)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.7 Kaggle House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, folder, sha1_hash=None):\n",
    "    \"\"\"Download a file to folder and return the local filepath.\"\"\"\n",
    "\n",
    "def extract(filename, folder):\n",
    "    \"\"\"Extract a zip/tar file into folder.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaggleHouse(d2l.DataModule):\n",
    "    def __init__(self, batch_size, train=None, val=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if self.train is None:\n",
    "            self.raw_train = pd.read_csv(d2l.download(\n",
    "                d2l.DATA_URL + 'kaggle_house_pred_train.csv', self.root,\n",
    "                sha1_hash='585e9cc93e70b39160e7921475f9bcd7d31219ce'))\n",
    "            self.raw_val = pd.read_csv(d2l.download(\n",
    "                d2l.DATA_URL + 'kaggle_house_pred_test.csv', self.root,\n",
    "                sha1_hash='fa19780a7b011d9b009e8bff8e99922a8ee2eb90'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = KaggleHouse(batch_size=64)\n",
    "print(data.raw_train.shape)\n",
    "print(data.raw_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.raw_train.iloc[:4, [0, 1, 2, 3, -3, -2, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(KaggleHouse)\n",
    "def preprocess(self):\n",
    "    # Remove the ID and label columns\n",
    "    label = 'SalePrice'\n",
    "    features = pd.concat(\n",
    "        (self.raw_train.drop(columns=['Id', label]),\n",
    "         self.raw_val.drop(columns=['Id'])))\n",
    "    # Standardize numerical columns\n",
    "    numeric_features = features.dtypes[features.dtypes!='object'].index\n",
    "    features[numeric_features] = features[numeric_features].apply(\n",
    "        lambda x: (x - x.mean()) / (x.std()))\n",
    "    # Replace NAN numerical features by 0\n",
    "    features[numeric_features] = features[numeric_features].fillna(0)\n",
    "    # Replace discrete features by one-hot encoding\n",
    "    features = pd.get_dummies(features, dummy_na=True)\n",
    "    # Save preprocessed features\n",
    "    self.train = features[:self.raw_train.shape[0]].copy()\n",
    "    self.train[label] = self.raw_train[label]\n",
    "    self.val = features[self.raw_train.shape[0]:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.preprocess()\n",
    "data.train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(KaggleHouse)\n",
    "def get_dataloader(self, train):\n",
    "    label = 'SalePrice'\n",
    "    data = self.train if train else self.val\n",
    "    if label not in data: return\n",
    "    get_tensor = lambda x: d2l.tensor(x.values.astype(float),\n",
    "                                      dtype=d2l.float32)\n",
    "    # Logarithm of prices \n",
    "    tensors = (get_tensor(data.drop(columns=[label])),  # X\n",
    "               d2l.reshape(d2l.log(get_tensor(data[label])), (-1, 1)))  # Y\n",
    "    return self.get_tensorloader(tensors, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_data(data, k):\n",
    "    rets = []\n",
    "    fold_size = data.train.shape[0] // k\n",
    "    for j in range(k):\n",
    "        idx = range(j * fold_size, (j+1) * fold_size)\n",
    "        rets.append(KaggleHouse(data.batch_size, data.train.drop(index=idx),  \n",
    "                                data.train.loc[idx]))    \n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(trainer, data, k, lr):\n",
    "    val_loss, models = [], []\n",
    "    for i, data_fold in enumerate(k_fold_data(data, k)):\n",
    "        model = d2l.LinearRegression(lr)\n",
    "        model.board.yscale='log'\n",
    "        if i != 0: model.board.display = False\n",
    "        trainer.fit(model, data_fold)\n",
    "        val_loss.append(float(model.board.data['val_loss'][-1].y))\n",
    "        models.append(model)\n",
    "    print(f'average validation log mse = {sum(val_loss)/len(val_loss)}')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = d2l.Trainer(max_epochs=10)\n",
    "models = k_fold(trainer, data, k=5, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [model(d2l.tensor(data.val.values.astype(float), dtype=d2l.float32))\n",
    "             for model in models]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (d2l)",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
