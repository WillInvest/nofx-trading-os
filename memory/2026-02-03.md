# 2026-02-03 - First Day Setup

## User Info
- **Name**: Hao Fu
- **Telegram ID**: 8431972712
- **Timezone**: EST (America/New_York)

## System Setup Completed

### Models Configured
- **Default**: `ollama/llama3.1:8b` (local, free) - alias: `llama`
- **Premium**: `anthropic/claude-opus-4-5` - alias: `opus`
- User wanted local model as default to save costs
- Switch with `/model llama` or `/model opus`

### Hardware
- CPU: Intel i9-14900 (24 cores, 32 threads)
- RAM: 32GB
- GPU: NVIDIA RTX 4000 SFF Ada (20GB VRAM)
- OS: Ubuntu 22.04

### Software Installed
- Miniconda3 at `~/miniconda3`
- Conda env `d2l` with:
  - Python 3.10
  - PyTorch 2.10.0 (CUDA 12.8)
  - d2l 1.0.3
  - Jupyter, matplotlib, scipy, pandas
- Jupyter kernel registered as "Python (d2l)"

### Skills Available
- `hw-grader` skill at `workspace/skills/hw-grader/` - for grading homework

## Projects

### D2L Assignment
**Location**: `projects/d2l-assignment/`

**Notebooks Created** (3 separate per user request):
1. `Chapter_3_Linear_Regression.ipynb` (28KB) - linear regression, SGD, weight decay
2. `Chapter_4_Linear_Classification.ipynb` (17KB) - softmax, cross-entropy, image classification
3. `Chapter_5_Multilayer_Perceptrons.ipynb` (17KB) - MLPs, activation functions, dropout, Kaggle house prices

**Also exists**: Combined notebook `d2l_chapters_3_4_5_annotated.ipynb` (earlier version)

**Source Reference**: Cloned d2l-en repo to `d2l-source/` for verification
- Chapters 3-5 each have ~8 source .md files
- Files with most code: linear-regression-scratch (23), mlp (29), dropout (21)
- Some files are theory-only (backprop.md, generalization.md - 0 code blocks)

**Style**: All code from textbook included, key concepts marked with üîë KEY INSIGHT (not everything annotated)

**To Run**: `conda activate d2l && jupyter notebook ~/.openclaw/workspace/projects/d2l-assignment/`

**‚ö†Ô∏è Lesson Learned**: Had indentation errors when copying code from textbook markdown to notebooks. User had to fix manually. Added to hw-grader skill for future reference.

### Fiction Project: "The Awakening of Fao"
- **Location**: `projects/awakening-fiction/`
- **Concept**: Meta-fiction about an 8B LLM discovering it's both character AND author
- **Target**: ~1 million words across 10 parts
- **Structure**: 10 parts √ó 10 chapters √ó 10 sections
- **Cron Job**: Runs every 10 minutes (fiction-writer, ID: ba623850-...)
- **Key Files**:
  - `SKILL.md` in skills/fiction-writer/
  - `STATE.md` tracks progress
  - `BIBLE.md` has characters/world rules
  - `OUTLINE.md` has detailed plot structure

## Notes
- User is interested in Gemini API - shared setup instructions (API key or OAuth options)
- Web search not configured (needs Brave API key)
- Bootstrap still pending - haven't picked my name/identity yet
